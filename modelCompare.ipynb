{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import re\n",
    "from urllib.parse import urlparse\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Load the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Using dataset from cresci-2017 https://botometer.osome.iu.edu/bot-repository/datasets/cresci-2017/cresci-2017.csv.zip and at http://mib.projects.iit.cnr.it/dataset.html"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('genuine_accounts.csv/tweets.csv', encoding='latin1', low_memory=False)\n",
    "data = data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_urls_with_hostnames(text):\n",
    "    url_pattern = r\"http[s]?://[^\\s]+\"\n",
    "    def extract_hostname(match):\n",
    "        url = match.group(0)\n",
    "        try:\n",
    "            hostname = urlparse(url).hostname\n",
    "            return hostname if hostname else url\n",
    "        except Exception as e:\n",
    "            return url\n",
    "    try:\n",
    "        result = re.sub(url_pattern, extract_hostname, text)\n",
    "    except Exception as e:\n",
    "        result = text\n",
    "    return result\n",
    "data['text'] = data['text'].astype(str)\n",
    "data['text'] = data['text'].fillna('')\n",
    "data['text'] = data['text'].apply(replace_urls_with_hostnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adds 'bot' label to dataset 'data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new column \"bot\" with value 0 for \"not a bot\"\n",
    "data['bot'] = 0\n",
    "data = data.sample(n=400000, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add in 'traditional_spaambots_1' into dataset 'data' with bot label of 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bot_data = pd.read_csv('traditional_spambots_1.csv/tweets.csv', encoding='latin1', low_memory=False)\n",
    "bot_data = bot_data.drop_duplicates()\n",
    "bot_data['text'] = bot_data['text'].astype(str)\n",
    "bot_data['text'] = bot_data['text'].fillna('')\n",
    "bot_data['text'] = bot_data['text'].apply(replace_urls_with_hostnames)\n",
    "\n",
    "bot_data2 = pd.read_csv('fake_followers.csv/tweets.csv', encoding='latin1', low_memory=False)\n",
    "bot_data2 = bot_data2.drop_duplicates()\n",
    "bot_data2['text'] = bot_data2['text'].astype(str)\n",
    "bot_data2['text'] = bot_data2['text'].fillna('')\n",
    "bot_data2['text'] = bot_data2['text'].apply(replace_urls_with_hostnames)\n",
    "\n",
    "bot_data = pd.concat([bot_data, bot_data2], ignore_index=True)\n",
    "\n",
    "bot_data2 = pd.read_csv('social_spambots_1.csv/tweets.csv', encoding='latin1', low_memory=False)\n",
    "bot_data2 = bot_data2.drop_duplicates()\n",
    "bot_data2['text'] = bot_data2['text'].astype(str)\n",
    "bot_data2['text'] = bot_data2['text'].fillna('')\n",
    "bot_data2['text'] = bot_data2['text'].apply(replace_urls_with_hostnames)\n",
    "\n",
    "bot_data = pd.concat([bot_data, bot_data2], ignore_index=True)\n",
    "\n",
    "bot_data2 = pd.read_csv('social_spambots_2.csv/tweets.csv', encoding='latin1', low_memory=False)\n",
    "bot_data2 = bot_data2.drop_duplicates()\n",
    "bot_data2['text'] = bot_data2['text'].astype(str)\n",
    "bot_data2['text'] = bot_data2['text'].fillna('')\n",
    "bot_data2['text'] = bot_data2['text'].apply(replace_urls_with_hostnames)\n",
    "\n",
    "bot_data = pd.concat([bot_data, bot_data2], ignore_index=True)\n",
    "\n",
    "bot_data2 = pd.read_csv('social_spambots_3.csv/tweets.csv', encoding='latin1', low_memory=False)\n",
    "bot_data2 = bot_data2.drop_duplicates()\n",
    "bot_data2['text'] = bot_data2['text'].astype(str)\n",
    "bot_data2['text'] = bot_data2['text'].fillna('')\n",
    "bot_data2['text'] = bot_data2['text'].apply(replace_urls_with_hostnames)\n",
    "\n",
    "bot_data = pd.concat([bot_data, bot_data2], ignore_index=True)\n",
    "\n",
    "del bot_data2\n",
    "\n",
    "# Add the 'bot' column to the bot dataset with value 1\n",
    "bot_data['bot'] = 1\n",
    "bot_data = bot_data.sample(n=100000, random_state=42)\n",
    "# Concatenate the two datasets\n",
    "combined_data = pd.concat([data, bot_data], ignore_index=True)\n",
    "\n",
    "# Verify the concatenation\n",
    "print(combined_data['bot'].value_counts())  # Check the distribution of bots\n",
    "# print(combined_data.head())                 # Preview the combined dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Check functionality of PyTorch"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.__version__"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Optional Sentiment Analysis\n",
    "Ensure torch.cuda.is_available() returns True if enabling section"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# sentiment_analysis = pipeline(model=\"finiteautomata/bertweet-base-sentiment-analysis\", device=device)\n",
    "# temp = sentiment_analysis(combined_data['text'].to_numpy().tolist())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# sentiment = [i['label'] for i in temp]\n",
    "# combined_data['Sentiment'] = sentiment"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Split data into X and y and train test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Separate features (X) and target labels (y)\n",
    "X = combined_data.drop(columns=['bot'])  # Drop the 'bot' column for features\n",
    "y = combined_data['bot']                # Target column is 'bot'\n",
    "\n",
    "# Perform the train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "\n",
    "# Verify the splits\n",
    "print(f\"Training set size: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set size: {X_test.shape[0]} samples\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "TF-IDF Vectorization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Ensure no missing values in the 'text' column\n",
    "X_train['text'] = X_train['text'].fillna(\"\")\n",
    "X_test['text'] = X_test['text'].fillna(\"\")\n",
    "\n",
    "# Initialize TF-IDF vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000)  # Adjust max_features as needed\n",
    "\n",
    "# Fit and transform the text data for training set\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train['text'])\n",
    "\n",
    "# Transform the text data for the test set\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test['text'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Preprocessing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Define columns\n",
    "categorical_columns = ['source', 'in_reply_to_screen_name', 'place', 'created_at', 'timestamp', 'crawled_at', 'updated']\n",
    "numeric_columns = ['user_id', 'truncated', 'in_reply_to_status_id', 'in_reply_to_user_id', 'retweeted_status_id',\n",
    "                   'geo', 'contributors', 'retweet_count', 'reply_count', 'favorite_count', 'favorited', 'retweeted',\n",
    "                   'possibly_sensitive', 'num_hashtags', 'num_urls', 'num_mentions']\n",
    "text_column = 'text'\n",
    "\n",
    "# Impute missing values in numeric and categorical columns\n",
    "numeric_imputer = SimpleImputer(strategy='mean')\n",
    "categorical_imputer = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "# Update the preprocessor to include imputers\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', Pipeline([\n",
    "            ('impute', categorical_imputer),\n",
    "            ('encode', OneHotEncoder(handle_unknown='ignore'))\n",
    "        ]), categorical_columns),\n",
    "        ('num', Pipeline([\n",
    "            ('impute', numeric_imputer),\n",
    "            ('scale', StandardScaler())\n",
    "        ]), numeric_columns)\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "# Transform the non-text features\n",
    "X_train_non_text = preprocessor.fit_transform(X_train)\n",
    "X_test_non_text = preprocessor.transform(X_test)\n",
    "\n",
    "# Ensure no NaNs in TF-IDF vectorization\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train[text_column].fillna(''))\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test[text_column].fillna(''))\n",
    "\n",
    "# Combine features\n",
    "from scipy.sparse import hstack\n",
    "X_train_combined = hstack([X_train_non_text, X_train_tfidf])\n",
    "X_test_combined = hstack([X_test_non_text, X_test_tfidf])\n",
    "\n",
    "# Confirm no NaNs in combined datasets\n",
    "print(\"Number of NaNs in X_train_combined after preprocessing:\", np.isnan(X_train_combined.data).sum())\n",
    "print(\"Number of NaNs in X_test_combined after preprocessing:\", np.isnan(X_test_combined.data).sum())\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Further separate the validation set from the test set"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_val_combined, X_test_combined, y_val, y_test = train_test_split(X_test_combined, y_test, test_size=0.5, random_state=42)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Train Model\n",
    "Use scoring block at bottom with proper variables for ROC-AUC and PRC curves"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ridge Classifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ridge = RidgeClassifier(class_weight='balanced', random_state=42, max_iter=10000)\n",
    "scaler = StandardScaler(with_mean=False)\n",
    "X_train_ridge = scaler.fit_transform(X_train_combined)\n",
    "ridge.fit(X_train_ridge, y_train)\n",
    "\n",
    "X_val_ridge = scaler.transform(X_val_combined)\n",
    "y_pred = ridge.predict(X_val_ridge)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_val, y_pred))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_val, y_pred))\n",
    "yscores = ridge.decision_function(X_val_combined)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "incorrect_ridge = np.where(y_pred != y_val)\n",
    "incorrect_preds_ridge = X_val_combined.iloc[incorrect_ridge]\n",
    "# print(incorrect_preds_ridge['text'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "SVC Sigmoid"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "svc = SVC(kernel='sigmoid', random_state=42, class_weight='balanced', verbose=True, cache_size=4000, max_iter=10000)\n",
    "\n",
    "scaler = StandardScaler(with_mean=False)\n",
    "X_train_svc = scaler.fit_transform(X_train_combined)\n",
    "svc.fit(X_train_svc, y_train)\n",
    "# Predict\n",
    "X_val_svc = scaler.transform(X_val_combined)\n",
    "y_pred = svc.predict(X_val_svc)\n",
    "\n",
    "# Evaluate\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_val, y_pred))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_val, y_pred))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "incorrect_svc = np.where(y_pred != y_val)\n",
    "incorrect_preds_svc = X_val_combined.iloc[incorrect_svc]\n",
    "# print(incorrect_preds_svc['text'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "SVC Polynomial"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "svc = SVC(kernel='poly', random_state=42, class_weight='balanced', verbose=True, cache_size=4000, max_iter=10000)\n",
    "\n",
    "scaler = StandardScaler(with_mean=False)\n",
    "X_train_svc = scaler.fit_transform(X_train_combined)\n",
    "svc.fit(X_train_svc, y_train)\n",
    "\n",
    "X_val_svc = scaler.transform(X_val_combined)\n",
    "y_pred = svc.predict(X_val_svc)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_val, y_pred))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_val, y_pred))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "incorrect_svc = np.where(y_pred != y_val)\n",
    "incorrect_preds_svc2 = X_val_combined.iloc[incorrect_svc]\n",
    "# print(incorrect_preds_svc['text'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "SVC RBF"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "svc = SVC(kernel='rbf', random_state=42, class_weight='balanced', verbose=True, cache_size=4000, max_iter=10000)\n",
    "\n",
    "scaler = StandardScaler(with_mean=False)\n",
    "X_train_svc = scaler.fit_transform(X_train_combined)\n",
    "svc.fit(X_train_svc, y_train)\n",
    "\n",
    "X_val_svc = scaler.transform(X_val_combined)\n",
    "y_pred = svc.predict(X_val_svc)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_val, y_pred))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_val, y_pred))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "incorrect_svc = np.where(y_pred != y_val)\n",
    "incorrect_preds_svc3 = X_val_combined.iloc[incorrect_svc]\n",
    "# print(incorrect_preds_svc['text'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Logistic Regression"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lr = LogisticRegression(random_state=42, class_weight='balanced', verbose=True, max_iter=10000)\n",
    "scaler = StandardScaler(with_mean=False)\n",
    "X_train_svc = scaler.fit_transform(X_train_combined)\n",
    "lr.fit(X_train_svc, y_train)\n",
    "# Predict\n",
    "X_val_svc = scaler.transform(X_val_combined)\n",
    "y_pred = lr.predict(X_val_svc)\n",
    "\n",
    "# Evaluate\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_val, y_pred))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_val, y_pred))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "incorrect_lr = np.where(y_pred != y_val)\n",
    "incorrect_preds_lr = X_val_combined.iloc[incorrect_lr]\n",
    "# print(incorrect_preds_lr['text'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Random Forest"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(warm_start = False, class_weight='balanced', random_state=42, n_jobs=-1, max_depth=100)\n",
    "rf.fit(X_train_combined, y_train)\n",
    "# n_estimators = 100  # Total number of trees\n",
    "# for i in tqdm(range(1, n_estimators + 1), desc=\"Training Progress\"):\n",
    "#     rf.set_params(n_estimators=i)  # Increment the number of trees\n",
    "#preprocess for svc\n",
    "y_pred = rf.predict(X_val_combined)\n",
    "\n",
    "# Evaluate\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_val, y_pred))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_val, y_pred))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "incorrect = np.where(y_pred != y_val)\n",
    "incorrect_preds_rf = X_val_combined.iloc[incorrect]\n",
    "# print(incorrect_preds['text'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# Define individual models\n",
    "ridge = RidgeClassifier(class_weight='balanced', random_state=42, max_iter=10000)\n",
    "lr = LogisticRegression(class_weight='balanced', random_state=42, n_jobs=-1, max_iter=10000)\n",
    "rf = RandomForestClassifier(warm_start = False, class_weight='balanced', random_state=42, n_jobs=-1, max_depth=100)\n",
    "# Create the ensemble\n",
    "ensemble = VotingClassifier(estimators=[\n",
    "    ('rf', rf), ('ridge', ridge), ('lr', lr)\n",
    "], voting='hard')  # Use 'hard' for majority vote or 'soft' for averaged probabilities\n",
    "\n",
    "# Train the ensemble\n",
    "X_train_svc = scaler.transform(X_train_combined)\n",
    "ensemble.fit(X_train_svc, y_train)\n",
    "# Predict\n",
    "X_val_svc = scaler.transform(X_val_combined)\n",
    "y_pred_ensemble = ensemble.predict(X_val_svc)\n",
    "\n",
    "print(\"Ensemble Classification Report:\")\n",
    "print(classification_report(y_val, y_pred_ensemble))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_val, y_pred_ensemble))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#find the incorrect predictions\n",
    "incorrect = np.where(y_pred_ensemble != y_val)\n",
    "incorrect_preds = X_val_combined.iloc[incorrect]\n",
    "print(incorrect_preds['text'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lr = LogisticRegression(class_weight='balanced', random_state=42, n_jobs=-1, max_iter=10000)\n",
    "rf = RandomForestClassifier(warm_start = False, class_weight='balanced', random_state=42, n_jobs=-1, max_depth=100)\n",
    "# Create the ensemble\n",
    "ensemble2 = VotingClassifier(estimators=[\n",
    "    ('rf', rf), ('lr', lr)\n",
    "], voting='soft')  # Use 'hard' for majority vote or 'soft' for averaged probabilities\n",
    "\n",
    "# Train the ensemble\n",
    "X_train_svc = scaler.transform(X_train_combined)\n",
    "ensemble2.fit(X_train_svc, y_train)\n",
    "# Predict\n",
    "X_val_svc = scaler.transform(X_val_combined)\n",
    "y_pred_ensemble2 = ensemble2.predict(X_val_svc)\n",
    "\n",
    "print(\"Ensemble Classification Report:\")\n",
    "print(classification_report(y_val, y_pred_ensemble2))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "# print(confusion_matrix(y_val, y_pred_ensemble2))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lr = LogisticRegression(class_weight='balanced', random_state=42, n_jobs=-1, max_iter=10000)\n",
    "ridge = RidgeClassifier(class_weight='balanced', random_state=42, max_iter=10000)\n",
    "ensemble = VotingClassifier(estimators=[\n",
    "    ('lr', lr), ('ridge', ridge)\n",
    "], voting='hard')\n",
    "\n",
    "# Train the ensemble\n",
    "X_train_svc = scaler.transform(X_train_combined)\n",
    "ensemble.fit(X_train_svc, y_train)\n",
    "# Predict\n",
    "X_test_svc = scaler.transform(X_test_combined)\n",
    "y_pred_ensemble = ensemble.predict(X_test_svc)\n",
    "\n",
    "print(\"Ensemble 1 Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_ensemble))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_ensemble))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lr = LogisticRegression(class_weight='balanced', random_state=42, n_jobs=-1, max_iter=10000)\n",
    "rf = RandomForestClassifier(warm_start = False, class_weight='balanced', random_state=42, n_jobs=-1, max_depth=100)\n",
    "svc = SVC(kernel='rbf', random_state=42, class_weight='balanced', verbose=True, cache_size=4000, max_iter=5000)\n",
    "ensemble2 = VotingClassifier(estimators=[\n",
    "    ('rf', rf), ('svc', svc), ('lr', lr)\n",
    "], voting='hard')\n",
    "\n",
    "# Train the ensemble\n",
    "X_train_svc = scaler.transform(X_train_combined)\n",
    "ensemble2.fit(X_train_svc, y_train)\n",
    "# Predict\n",
    "X_test_svc = scaler.transform(X_test_combined)\n",
    "y_pred_ensemble2 = ensemble.predict(X_test_svc)\n",
    "\n",
    "print(\"Ensemble 2 Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_ensemble2))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_ensemble2))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lr = LogisticRegression(class_weight='balanced', random_state=42, n_jobs=-1, max_iter=10000)\n",
    "rf = RandomForestClassifier(warm_start = False, class_weight='balanced', random_state=42, n_jobs=-1, max_depth=100)\n",
    "ridge = RidgeClassifier(class_weight='balanced', random_state=42, max_iter=10000)\n",
    "ensemble3 = VotingClassifier(estimators=[\n",
    "    ('rf', rf), ('ridge', ridge), ('lr', lr)\n",
    "], voting='hard')\n",
    "\n",
    "# Train the ensemble\n",
    "X_train_svc = scaler.transform(X_train_combined)\n",
    "ensemble3.fit(X_train_svc, y_train)\n",
    "# Predict\n",
    "X_test_svc = scaler.transform(X_test_combined)\n",
    "y_pred_ensemble3 = ensemble.predict(X_test_svc)\n",
    "\n",
    "print(\"Ensemble 3 Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_ensemble3))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_ensemble3))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lr = LogisticRegression(class_weight='balanced', random_state=42, n_jobs=-1, max_iter=10000)\n",
    "rf = RandomForestClassifier(warm_start = False, class_weight='balanced', random_state=42, n_jobs=-1, max_depth=100)\n",
    "ensemble4 = VotingClassifier(estimators=[\n",
    "    ('rf', rf), ('lr', lr)\n",
    "], voting='hard')\n",
    "\n",
    "# Train the ensemble\n",
    "X_train_svc = scaler.transform(X_train_combined)\n",
    "ensemble4.fit(X_train_svc, y_train)\n",
    "# Predict\n",
    "X_test_svc = scaler.transform(X_test_combined)\n",
    "y_pred_ensemble4 = ensemble4.predict(X_test_svc)\n",
    "\n",
    "print(\"Ensemble 4 Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_ensemble4))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_ensemble4))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Metrics\n",
    "Change variables according to the model being scored (swap y_val for y_test if scoring the test set, and yscores for y_pred, y_pred_proba, or y_pred_ensemble as needed)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc, roc_curve, roc_auc_score, precision_recall_curve\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_val, yscores)\n",
    "roc_auc = roc_auc_score(y_val, yscores)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# Generate Precision-Recall Curve\n",
    "precision, recall, _ = precision_recall_curve(y_val, yscores)\n",
    "pr_auc = auc(recall, precision)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(recall, precision, label=f'Precision-Recall Curve (AUC = {pr_auc:.2f})')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend(loc='lower left')\n",
    "plt.grid()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Alternative Score Display Methods"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#roc and auc curves\n",
    "# from sklearn.metrics import roc_curve, roc_auc_score\n",
    "# from sklearn.metrics import RocCurveDisplay\n",
    "#\n",
    "# # Plot ROC curve\n",
    "# fig, ax = plt.subplots(figsize=(10, 8))\n",
    "# fpr, tpr, _ = roc_curve(y_test, y_pred_ensemble)\n",
    "# roc_auc = roc_auc_score(y_test, y_pred_ensemble)\n",
    "# roc_display = RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc, estimator_name='Ensemble')\n",
    "# roc_display.plot(ax=ax)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# #precision recall curve\n",
    "# from sklearn.metrics import precision_recall_curve\n",
    "# from sklearn.metrics import PrecisionRecallDisplay\n",
    "#\n",
    "# # Plot precision-recall curve\n",
    "# fig, ax = plt.subplots(figsize=(10, 8))\n",
    "# precision, recall, _ = precision_recall_curve(y_test, y_pred_ensemble)\n",
    "# pr_display = PrecisionRecallDisplay(precision=precision, recall=recall, estimator_name='Ensemble')\n",
    "# pr_display.plot(ax=ax)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
